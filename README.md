# üë®‚Äçüíª [Your Name/Handle] 
### AI Researcher | Financial ML & Multimodal Agents

I investigate the intersection of **Machine Learning** and **Complex Systems**, with a focus on **Reinforcement Learning** for autonomous decision-making and **Multimodal LLMs** for human-computer interaction. My work prioritizes **interpretable theoretical rigor** over black-box complexity.

---

## üéØ Selected Research

### üìà [HOPE - Probabilistic Stock Screening System](https://github.com/Joeytribb/HOPE)
> **Question**: Can simple linear models outperform Deep Learning in short-term volatility prediction?

A comparative analysis of ML architectures for predicting short-term alpha in high-volatility markets.
*   **Key Finding**: Linear Regression **outperformed LSTM and Random Forest** by achieving a **70% Win Rate** and **190% Return** in backtests, demonstrating that model simplicity often generalizes better in stochastic financial environments.
*   **Tech Stack**: `scikit-learn`, `pandas`, `Linear Regression`, `LSTM`.
*   ![Performance](./assets/hope_results.png)

### üß† [Bithax - Deep RL High-Frequency Trading](https://github.com/Joeytribb/bithax)
> **System**: PPO-based autonomous agent for Bitcoin HFT with 0.05% fee constraints.

End-to-end continuous control agent trained on 1-hour Bitcoin OHLCV data.
*   **Architecture**: Proximal Policy Optimization (PPO) with separate Value/Policy heads.
*   **Innovation**: Reward shaping that penalizes drawdown and incorporates transaction costs directly into the value function.
*   **Performance**: Demonstrated ability to identify profitable regimes while "sitting out" low-confidence volatility.
*   **Tech Stack**: `PyTorch`, `Stable-Baselines3`, `Gymnasium`, `Pandas`.
*   ![Agent Profile](./assets/bithax_profile.png)
*   ![Trading Animation](./assets/bithax_demo.gif)

### üëÅÔ∏è [Jaguu - Multimodal LLM Assistant](https://github.com/Joeytribb/Jaguu)
> **Agent**: Voice-and-Vision capable AI assistant running locally.

An attempt to build a privacy-first, local multimodal agent.
*   **Capabilities**: Real-time **Image Description** (via Vision LLMs) and **Voice Interaction** (Whisper + TTS).
*   **Use Case**: Accessible technology for the visually impaired.
*   **Tech Stack**: `Ollama`, `Llama-3`, `Whisper`, `Python`.

---

## üß™ Experimental & Engineering Projects

*   **[TMgo - Deep-RL Autonomous Racing](https://github.com/Joeytribb/TMgo)**: Training a DQN agent to master *Trackmania Nations Forever* using raw pixel inputs and Lidar sensors. Demonstrates complex continuous control.
*   **[Indus_valley - Archeo-Vision Clustering](https://github.com/Joeytribb/Indus_valley)**: Utilizing unsupervised clustering (K-Means) to categorize and analyze ancient scripts from the Indus Valley civilization.

---

## üõ†Ô∏è Technical Arsenal

| Domain | Tools & Frameworks |
| :--- | :--- |
| **Deep Learning** | PyTorch, TensorFlow, Keras, Stable-Baselines3 |
| **Data Science** | Pandas, NumPy, Scikit-learn, Matplotlib, Plotly |
| **Systems** | Docker, Git, Linux, Arduino, C |
| **LLMs** | Ollama, Llama-3, LangChain, HuggingFace |

---

### üì¨ Contact
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/yourprofile) 
[![Google Scholar](https://img.shields.io/badge/Google_Scholar-Citations-gray?style=for-the-badge&logo=google-scholar)](https://scholar.google.com)
